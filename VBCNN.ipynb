{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 28,28\n",
    "\n",
    "#defining the data directories\n",
    "train_data_dir= 'data/training_set'\n",
    "validation_data_dir= 'data/test_set'\n",
    "n_training_sample= 4000\n",
    "n_validation_sample= 1000\n",
    "epochs=20\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 3)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(256, activation=tf.nn.relu),  \n",
    "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the optimizer and metrics\n",
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8005 images belonging to 2 classes.\n",
      "Found 2023 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "40/40 [==============================] - 33s 821ms/step - loss: 0.6831 - accuracy: 0.5526 - val_loss: 0.6509 - val_accuracy: 0.5970\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 33s 830ms/step - loss: 0.6447 - accuracy: 0.6325 - val_loss: 0.6894 - val_accuracy: 0.5810\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 36s 889ms/step - loss: 0.6218 - accuracy: 0.6557 - val_loss: 0.6705 - val_accuracy: 0.6040\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 35s 864ms/step - loss: 0.5894 - accuracy: 0.6868 - val_loss: 0.5962 - val_accuracy: 0.6810\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 35s 876ms/step - loss: 0.5880 - accuracy: 0.6848 - val_loss: 0.5612 - val_accuracy: 0.7240\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 36s 896ms/step - loss: 0.5925 - accuracy: 0.6823 - val_loss: 0.6664 - val_accuracy: 0.6610\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 33s 821ms/step - loss: 0.5635 - accuracy: 0.6983 - val_loss: 0.6064 - val_accuracy: 0.6830\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 33s 832ms/step - loss: 0.5805 - accuracy: 0.6899 - val_loss: 0.5565 - val_accuracy: 0.7260\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 32s 801ms/step - loss: 0.5530 - accuracy: 0.7129 - val_loss: 0.5826 - val_accuracy: 0.6960\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 35s 863ms/step - loss: 0.5541 - accuracy: 0.7117 - val_loss: 0.5313 - val_accuracy: 0.7300\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 35s 877ms/step - loss: 0.5291 - accuracy: 0.7395 - val_loss: 0.5731 - val_accuracy: 0.6960\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 38s 951ms/step - loss: 0.5436 - accuracy: 0.7204 - val_loss: 0.5293 - val_accuracy: 0.7380\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 34s 860ms/step - loss: 0.5255 - accuracy: 0.7321 - val_loss: 0.5575 - val_accuracy: 0.6980\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 37s 921ms/step - loss: 0.5305 - accuracy: 0.7383 - val_loss: 0.5217 - val_accuracy: 0.7460\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 24s 602ms/step - loss: 0.5221 - accuracy: 0.7396 - val_loss: 0.5765 - val_accuracy: 0.7090\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 19s 478ms/step - loss: 0.5115 - accuracy: 0.7498 - val_loss: 0.5417 - val_accuracy: 0.7230\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 20s 497ms/step - loss: 0.4982 - accuracy: 0.7608 - val_loss: 0.5287 - val_accuracy: 0.7400\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 20s 488ms/step - loss: 0.5010 - accuracy: 0.7575 - val_loss: 0.6334 - val_accuracy: 0.6910\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 20s 491ms/step - loss: 0.4876 - accuracy: 0.7659 - val_loss: 0.5247 - val_accuracy: 0.7540\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 24s 601ms/step - loss: 0.4805 - accuracy: 0.7695 - val_loss: 0.5630 - val_accuracy: 0.7230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23bf413ceb0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=n_training_sample // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=n_validation_sample // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "#testing the model\n",
    "pred= image.load_img('data/dog_1.jpg', target_size=(28,28))\n",
    "pred=image.img_to_array(pred)\n",
    "pred= np.expand_dims(pred, axis=0)\n",
    "result= model.predict(pred)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
